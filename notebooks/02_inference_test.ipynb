{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab1db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be3943c",
   "metadata": {},
   "source": [
    "## 1. Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb990652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from ../models/sentiment_model.pkl\n",
      "\n",
      "Model pipeline steps:\n",
      "  - tfidf: TfidfVectorizer\n",
      "  - classifier: LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = \"../models/sentiment_model.pkl\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Model file not found at {model_path}\")\n",
    "    print(\"Please train the model first using the training notebook or script.\")\n",
    "else:\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"Model loaded successfully from {model_path}\")\n",
    "    print(\"\\nModel pipeline steps:\")\n",
    "    for name, step in model.named_steps.items():\n",
    "        print(f\"  - {name}: {type(step).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55df4022",
   "metadata": {},
   "source": [
    "## 2. Single Text Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4661fd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This product is absolutely amazing! I love it!\n",
      "\n",
      "Prediction: POSITIVE\n",
      "\n",
      "Probabilities:\n",
      "  Negative: 0.0170\n",
      "  Positive: 0.0170\n",
      "\n",
      "Confidence: 96.60%\n"
     ]
    }
   ],
   "source": [
    "# Test with a single text\n",
    "text = \"This product is absolutely amazing! I love it!\"\n",
    "\n",
    "prediction = model.predict([text])[0]\n",
    "probabilities = model.predict_proba([text])[0]\n",
    "\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"\\nPrediction: {prediction.upper()}\")\n",
    "print(\"\\nProbabilities:\")\n",
    "print(f\"  Negative: {probabilities[0]:.4f}\")\n",
    "print(f\"  Positive: {probabilities[1]:.4f}\")\n",
    "print(f\"\\nConfidence: {max(probabilities):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e89240",
   "metadata": {},
   "source": [
    "## 3. Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f369cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Prediction Results:\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Confidence</th>\n",
       "      <th>Negative_Prob</th>\n",
       "      <th>Positive_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent product! Highly recommend!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.778449</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.077987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible experience. Very disappointed.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.856062</td>\n",
       "      <td>0.856062</td>\n",
       "      <td>0.089819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good quality for the price.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.636698</td>\n",
       "      <td>0.199373</td>\n",
       "      <td>0.636698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't waste your money on this.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.886470</td>\n",
       "      <td>0.886470</td>\n",
       "      <td>0.054752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best purchase I've made this year!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.900833</td>\n",
       "      <td>0.049708</td>\n",
       "      <td>0.049459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Poor quality. Broke after one use.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.908097</td>\n",
       "      <td>0.908097</td>\n",
       "      <td>0.033640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Love it! Works perfectly.</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.722881</td>\n",
       "      <td>0.098470</td>\n",
       "      <td>0.178649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not worth it. Save your money.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.817878</td>\n",
       "      <td>0.817878</td>\n",
       "      <td>0.058647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Outstanding performance and value!</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.842422</td>\n",
       "      <td>0.080375</td>\n",
       "      <td>0.077204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Completely useless product.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.622108</td>\n",
       "      <td>0.622108</td>\n",
       "      <td>0.185900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Text Prediction  Confidence  \\\n",
       "0     Excellent product! Highly recommend!   positive    0.778449   \n",
       "1  Terrible experience. Very disappointed.   negative    0.856062   \n",
       "2              Good quality for the price.    neutral    0.636698   \n",
       "3          Don't waste your money on this.   negative    0.886470   \n",
       "4       Best purchase I've made this year!   positive    0.900833   \n",
       "5       Poor quality. Broke after one use.   negative    0.908097   \n",
       "6                Love it! Works perfectly.   positive    0.722881   \n",
       "7           Not worth it. Save your money.   negative    0.817878   \n",
       "8       Outstanding performance and value!   positive    0.842422   \n",
       "9              Completely useless product.   negative    0.622108   \n",
       "\n",
       "   Negative_Prob  Positive_Prob  \n",
       "0       0.143564       0.077987  \n",
       "1       0.856062       0.089819  \n",
       "2       0.199373       0.636698  \n",
       "3       0.886470       0.054752  \n",
       "4       0.049708       0.049459  \n",
       "5       0.908097       0.033640  \n",
       "6       0.098470       0.178649  \n",
       "7       0.817878       0.058647  \n",
       "8       0.080375       0.077204  \n",
       "9       0.622108       0.185900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test with multiple texts\n",
    "test_texts = [\n",
    "    \"Excellent product! Highly recommend!\",\n",
    "    \"Terrible experience. Very disappointed.\",\n",
    "    \"Good quality for the price.\",\n",
    "    \"Don't waste your money on this.\",\n",
    "    \"Best purchase I've made this year!\",\n",
    "    \"Poor quality. Broke after one use.\",\n",
    "    \"Love it! Works perfectly.\",\n",
    "    \"Not worth it. Save your money.\",\n",
    "    \"Outstanding performance and value!\",\n",
    "    \"Completely useless product.\"\n",
    "]\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_texts)\n",
    "probabilities = model.predict_proba(test_texts)\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': test_texts,\n",
    "    'Prediction': predictions,\n",
    "    'Confidence': [max(p) for p in probabilities],\n",
    "    'Negative_Prob': [p[0] for p in probabilities],\n",
    "    'Positive_Prob': [p[1] for p in probabilities]\n",
    "})\n",
    "\n",
    "# Display results\n",
    "print(\"Batch Prediction Results:\")\n",
    "print(\"=\" * 100)\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77f0214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction Summary:\n",
      "Total texts: 10\n",
      "Positive predictions: 4\n",
      "Negative predictions: 5\n",
      "\n",
      "Average confidence: 79.72%\n",
      "Min confidence: 62.21%\n",
      "Max confidence: 90.81%\n"
     ]
    }
   ],
   "source": [
    "# Summary statistics\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(f\"Total texts: {len(test_texts)}\")\n",
    "print(f\"Positive predictions: {sum(predictions == 'positive')}\")\n",
    "print(f\"Negative predictions: {sum(predictions == 'negative')}\")\n",
    "print(f\"\\nAverage confidence: {results_df['Confidence'].mean():.2%}\")\n",
    "print(f\"Min confidence: {results_df['Confidence'].min():.2%}\")\n",
    "print(f\"Max confidence: {results_df['Confidence'].max():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17ccdcd",
   "metadata": {},
   "source": [
    "## 4. Interactive Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2809e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Text: This is wonderful! I'm so happy with it!\n",
      "\n",
      "ðŸ˜Š Sentiment: POSITIVE\n",
      "Confidence: 77.3%\n",
      "\n",
      "Probabilities:\n",
      "  Negative: 10.8%\n",
      "  Positive: 12.0%\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interactive prediction function\n",
    "def predict_sentiment(text: str) -> None:\n",
    "    \"\"\"Predict sentiment for a given text.\"\"\"\n",
    "    if not text.strip():\n",
    "        print(\"Please enter some text.\")\n",
    "        return\n",
    "\n",
    "    prediction = model.predict([text])[0]\n",
    "    probabilities = model.predict_proba([text])[0]\n",
    "    confidence = max(probabilities) * 100\n",
    "\n",
    "    # Emoji based on sentiment\n",
    "    emoji = \"ðŸ˜Š\" if prediction == \"positive\" else \"ðŸ˜ž\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"\\n{emoji} Sentiment: {prediction.upper()}\")\n",
    "    print(f\"Confidence: {confidence:.1f}%\")\n",
    "    print(\"\\nProbabilities:\")\n",
    "    print(f\"  Negative: {probabilities[0]:.1%}\")\n",
    "    print(f\"  Positive: {probabilities[1]:.1%}\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Example usage\n",
    "predict_sentiment(\"This is wonderful! I'm so happy with it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41e0f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try your own text\n",
    "# Uncomment and modify the line below to test your own text\n",
    "# predict_sentiment(\"Your custom text here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104562fd",
   "metadata": {},
   "source": [
    "## 5. Test with Seldon-Compatible Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a1dbe46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seldon-format prediction:\n",
      "{\n",
      "  \"data\": {\n",
      "    \"names\": [\n",
      "      \"negative\",\n",
      "      \"positive\"\n",
      "    ],\n",
      "    \"ndarray\": [\n",
      "      \"neutral\",\n",
      "      \"negative\"\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"probabilities\": [\n",
      "      [\n",
      "        0.11396328636917727,\n",
      "        0.48745992575282143,\n",
      "        0.3985767878780013\n",
      "      ],\n",
      "      [\n",
      "        0.8940487369631132,\n",
      "        0.048701224693808345,\n",
      "        0.05725003834307856\n",
      "      ]\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Simulate Seldon input format\n",
    "def predict_seldon_format(texts: list) -> dict:\n",
    "    \"\"\"Make predictions in Seldon-compatible format.\"\"\"\n",
    "    predictions = model.predict(texts)\n",
    "    probabilities = model.predict_proba(texts)\n",
    "\n",
    "    # Format similar to Seldon response\n",
    "    return {\n",
    "        \"data\": {\n",
    "            \"names\": [\"negative\", \"positive\"],\n",
    "            \"ndarray\": predictions.tolist()\n",
    "        },\n",
    "        \"meta\": {\n",
    "            \"probabilities\": probabilities.tolist()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Test\n",
    "test_input = [\"Great product!\", \"Terrible quality.\"]\n",
    "result = predict_seldon_format(test_input)\n",
    "\n",
    "print(\"Seldon-format prediction:\")\n",
    "import json\n",
    "\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af45bcf0",
   "metadata": {},
   "source": [
    "## 6. Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d0450b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INFORMATION\n",
      "================================================================================\n",
      "Model path: ../models/sentiment_model.pkl\n",
      "Model type: Pipeline\n",
      "\n",
      "Pipeline steps:\n",
      "  1. tfidf: TfidfVectorizer\n",
      "     - Max features: 5000\n",
      "     - N-gram range: (1, 2)\n",
      "  2. classifier: LogisticRegression\n",
      "     - Algorithm: LogisticRegression\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display model information\n",
    "print(\"MODEL INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Model path: {model_path}\")\n",
    "print(f\"Model type: {type(model).__name__}\")\n",
    "print(\"\\nPipeline steps:\")\n",
    "for i, (name, step) in enumerate(model.named_steps.items(), 1):\n",
    "    print(f\"  {i}. {name}: {type(step).__name__}\")\n",
    "    if hasattr(step, 'get_params'):\n",
    "        params = step.get_params()\n",
    "        if name == 'tfidf':\n",
    "            print(f\"     - Max features: {params.get('max_features')}\")\n",
    "            print(f\"     - N-gram range: {params.get('ngram_range')}\")\n",
    "        elif name == 'classifier':\n",
    "            print(f\"     - Algorithm: {type(step).__name__}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b537e-c02c-40d2-bf01-3519c07af6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ff746d-1510-4614-99f5-f4edbc449034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
